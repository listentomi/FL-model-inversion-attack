# Federated Learning Model Inversion Attack
Demonstration of Model Inversion Attack Against Unsecure Personalized Federated Learning Framework

In this notebook we demonstrage a model inversion attack on a Personalized Federated Learning Framework to train models using. The split mode here enables us to create an attack model that will recover features from the embedding vector producted by the first layer in our CNN.
